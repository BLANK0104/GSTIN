{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe for X_train data and X_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('X_Train_Data_Input.csv')\n",
    "df3 = pd.read_csv('X_Test_Data_Input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Column0</th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>...</th>\n",
       "      <th>Column12</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad1a67e4cbddc767a3456b0d94299b9e</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>3726.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>0.434190</td>\n",
       "      <td>-0.015603</td>\n",
       "      <td>0.606265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7246d2f76ac0c217ec25e72ea5f014cb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>0.452580</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>1.554998</td>\n",
       "      <td>-0.015574</td>\n",
       "      <td>0.329946</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22ba388e7dd14c13342c49e75fc29dda</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>4543.0</td>\n",
       "      <td>-1.577453</td>\n",
       "      <td>-1.429540</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59f9b981472d97342587fb3e6392aeb1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f6317cf7ecf126859804eddff279aead</td>\n",
       "      <td>0.0</td>\n",
       "      <td>718</td>\n",
       "      <td>950.0</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  Column0  Column1  Column2   Column3  \\\n",
       "0  ad1a67e4cbddc767a3456b0d94299b9e      2.0     2495   3726.0  0.678139   \n",
       "1  7246d2f76ac0c217ec25e72ea5f014cb      0.0     2495   3454.0  0.452580   \n",
       "2  22ba388e7dd14c13342c49e75fc29dda      2.0     2495   4543.0 -1.577453   \n",
       "3  59f9b981472d97342587fb3e6392aeb1      0.0      211     59.0       NaN   \n",
       "4  f6317cf7ecf126859804eddff279aead      0.0      718    950.0 -2.028572   \n",
       "\n",
       "    Column4   Column5   Column6   Column7   Column8  ...  Column12  Column13  \\\n",
       "0  0.701403 -0.007468  0.434190 -0.015603  0.606265  ...         0         0   \n",
       "1  0.701403 -0.007468  1.554998 -0.015574  0.329946  ...         0         0   \n",
       "2 -1.429540 -0.007469 -0.407939 -0.015607 -0.774979  ...         1         1   \n",
       "3       NaN       NaN -0.407939 -0.015607 -0.774979  ...         0         0   \n",
       "4 -1.855728       NaN -0.407939 -0.015607 -0.774979  ...         0         0   \n",
       "\n",
       "   Column14  Column15  Column16  Column17  Column18  Column19  Column20  \\\n",
       "0  0.001351   0.00339       0.0         0       0.0         0         0   \n",
       "1  0.001351   0.00339       0.0         0       0.0         0         0   \n",
       "2  0.001351   0.00339       0.0         0       0.0         0         0   \n",
       "3       NaN   0.00339       0.0         0       1.0         0         0   \n",
       "4       NaN   0.00339       0.0         0       0.0         0         0   \n",
       "\n",
       "   Column21  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Column0</th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>...</th>\n",
       "      <th>Column12</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07cf2025382f6325b316e128b1b90999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.554860</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb972eb3a1f8d0d1a13f45e7c07d37d4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1579</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.142149</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee35e164b3ddc25a9f40243b81ad290d</td>\n",
       "      <td>0.0</td>\n",
       "      <td>898</td>\n",
       "      <td>3817.0</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28229ccd7bad7dd83324a4175a7e0531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>-0.675216</td>\n",
       "      <td>-0.577162</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.635264</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2f94873da2c332d28f111742818e0fbb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>646</td>\n",
       "      <td>6510.0</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015434</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  Column0  Column1  Column2   Column3  \\\n",
       "0  07cf2025382f6325b316e128b1b90999      1.0     1986     53.0  0.678139   \n",
       "1  eb972eb3a1f8d0d1a13f45e7c07d37d4      2.0     1579     12.0  0.678139   \n",
       "2  ee35e164b3ddc25a9f40243b81ad290d      0.0      898   3817.0 -2.028572   \n",
       "3  28229ccd7bad7dd83324a4175a7e0531      0.0       79   3449.0 -0.675216   \n",
       "4  2f94873da2c332d28f111742818e0fbb      1.0      646   6510.0 -2.028572   \n",
       "\n",
       "    Column4   Column5   Column6   Column7   Column8  ...  Column12  Column13  \\\n",
       "0  0.701403 -0.007469 -0.407939 -0.015607  0.554860  ...         1         1   \n",
       "1  0.701403 -0.007468 -0.407939 -0.015607  0.142149  ...         1         0   \n",
       "2 -1.855728       NaN -0.407939 -0.015607 -0.774979  ...         0         0   \n",
       "3 -0.577162 -0.007469  0.004020 -0.015607  0.635264  ...         0         1   \n",
       "4 -1.855728       NaN -0.407939 -0.015434 -0.774979  ...         1         1   \n",
       "\n",
       "   Column14  Column15  Column16  Column17  Column18  Column19  Column20  \\\n",
       "0  0.001351   0.00339       0.0         0       0.0         0         0   \n",
       "1  0.001351   0.00339       0.0         0       0.0         0         0   \n",
       "2       NaN   0.00339       0.0         0       0.0         0         0   \n",
       "3  0.001351   0.00339       0.0         0       0.0         0         0   \n",
       "4       NaN   0.00339       0.0         0       0.0         0         0   \n",
       "\n",
       "   Column21  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe for Y_train and Y_test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('Y_Train_Data_Target.csv')\n",
    "df4 = pd.read_csv('Y_Test_Data_Target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad1a67e4cbddc767a3456b0d94299b9e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7246d2f76ac0c217ec25e72ea5f014cb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22ba388e7dd14c13342c49e75fc29dda</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59f9b981472d97342587fb3e6392aeb1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f6317cf7ecf126859804eddff279aead</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  target\n",
       "0  ad1a67e4cbddc767a3456b0d94299b9e       0\n",
       "1  7246d2f76ac0c217ec25e72ea5f014cb       0\n",
       "2  22ba388e7dd14c13342c49e75fc29dda       0\n",
       "3  59f9b981472d97342587fb3e6392aeb1       1\n",
       "4  f6317cf7ecf126859804eddff279aead       0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07cf2025382f6325b316e128b1b90999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb972eb3a1f8d0d1a13f45e7c07d37d4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee35e164b3ddc25a9f40243b81ad290d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28229ccd7bad7dd83324a4175a7e0531</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2f94873da2c332d28f111742818e0fbb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  target\n",
       "0  07cf2025382f6325b316e128b1b90999       0\n",
       "1  eb972eb3a1f8d0d1a13f45e7c07d37d4       0\n",
       "2  ee35e164b3ddc25a9f40243b81ad290d       0\n",
       "3  28229ccd7bad7dd83324a4175a7e0531       0\n",
       "4  2f94873da2c332d28f111742818e0fbb       0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the input and target files of train and test file into their single dataframe respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge them into a single df\n",
    "\n",
    "df_train = pd.merge(df1, df2, on = 'ID', how = 'inner')\n",
    "df_test = pd.merge(df3, df4, on = 'ID', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Column0</th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>...</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ad1a67e4cbddc767a3456b0d94299b9e</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>3726.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>0.434190</td>\n",
       "      <td>-0.015603</td>\n",
       "      <td>0.606265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7246d2f76ac0c217ec25e72ea5f014cb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>0.452580</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>1.554998</td>\n",
       "      <td>-0.015574</td>\n",
       "      <td>0.329946</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22ba388e7dd14c13342c49e75fc29dda</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>4543.0</td>\n",
       "      <td>-1.577453</td>\n",
       "      <td>-1.429540</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59f9b981472d97342587fb3e6392aeb1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f6317cf7ecf126859804eddff279aead</td>\n",
       "      <td>0.0</td>\n",
       "      <td>718</td>\n",
       "      <td>950.0</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  Column0  Column1  Column2   Column3  \\\n",
       "0  ad1a67e4cbddc767a3456b0d94299b9e      2.0     2495   3726.0  0.678139   \n",
       "1  7246d2f76ac0c217ec25e72ea5f014cb      0.0     2495   3454.0  0.452580   \n",
       "2  22ba388e7dd14c13342c49e75fc29dda      2.0     2495   4543.0 -1.577453   \n",
       "3  59f9b981472d97342587fb3e6392aeb1      0.0      211     59.0       NaN   \n",
       "4  f6317cf7ecf126859804eddff279aead      0.0      718    950.0 -2.028572   \n",
       "\n",
       "    Column4   Column5   Column6   Column7   Column8  ...  Column13  Column14  \\\n",
       "0  0.701403 -0.007468  0.434190 -0.015603  0.606265  ...         0  0.001351   \n",
       "1  0.701403 -0.007468  1.554998 -0.015574  0.329946  ...         0  0.001351   \n",
       "2 -1.429540 -0.007469 -0.407939 -0.015607 -0.774979  ...         1  0.001351   \n",
       "3       NaN       NaN -0.407939 -0.015607 -0.774979  ...         0       NaN   \n",
       "4 -1.855728       NaN -0.407939 -0.015607 -0.774979  ...         0       NaN   \n",
       "\n",
       "   Column15  Column16  Column17  Column18  Column19  Column20  Column21  \\\n",
       "0   0.00339       0.0         0       0.0         0         0         0   \n",
       "1   0.00339       0.0         0       0.0         0         0         0   \n",
       "2   0.00339       0.0         0       0.0         0         0         0   \n",
       "3   0.00339       0.0         0       1.0         0         0         0   \n",
       "4   0.00339       0.0         0       0.0         0         0         0   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       1  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Column0</th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>...</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07cf2025382f6325b316e128b1b90999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.554860</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb972eb3a1f8d0d1a13f45e7c07d37d4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1579</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.142149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee35e164b3ddc25a9f40243b81ad290d</td>\n",
       "      <td>0.0</td>\n",
       "      <td>898</td>\n",
       "      <td>3817.0</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28229ccd7bad7dd83324a4175a7e0531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>-0.675216</td>\n",
       "      <td>-0.577162</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.635264</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2f94873da2c332d28f111742818e0fbb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>646</td>\n",
       "      <td>6510.0</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015434</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  Column0  Column1  Column2   Column3  \\\n",
       "0  07cf2025382f6325b316e128b1b90999      1.0     1986     53.0  0.678139   \n",
       "1  eb972eb3a1f8d0d1a13f45e7c07d37d4      2.0     1579     12.0  0.678139   \n",
       "2  ee35e164b3ddc25a9f40243b81ad290d      0.0      898   3817.0 -2.028572   \n",
       "3  28229ccd7bad7dd83324a4175a7e0531      0.0       79   3449.0 -0.675216   \n",
       "4  2f94873da2c332d28f111742818e0fbb      1.0      646   6510.0 -2.028572   \n",
       "\n",
       "    Column4   Column5   Column6   Column7   Column8  ...  Column13  Column14  \\\n",
       "0  0.701403 -0.007469 -0.407939 -0.015607  0.554860  ...         1  0.001351   \n",
       "1  0.701403 -0.007468 -0.407939 -0.015607  0.142149  ...         0  0.001351   \n",
       "2 -1.855728       NaN -0.407939 -0.015607 -0.774979  ...         0       NaN   \n",
       "3 -0.577162 -0.007469  0.004020 -0.015607  0.635264  ...         1  0.001351   \n",
       "4 -1.855728       NaN -0.407939 -0.015434 -0.774979  ...         1       NaN   \n",
       "\n",
       "   Column15  Column16  Column17  Column18  Column19  Column20  Column21  \\\n",
       "0   0.00339       0.0         0       0.0         0         0         0   \n",
       "1   0.00339       0.0         0       0.0         0         0         0   \n",
       "2   0.00339       0.0         0       0.0         0         0         0   \n",
       "3   0.00339       0.0         0       0.0         0         0         0   \n",
       "4   0.00339       0.0         0       0.0         0         0         0   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for missing values in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID               0\n",
       "Column0          9\n",
       "Column1          0\n",
       "Column2          0\n",
       "Column3     126303\n",
       "Column4     127710\n",
       "Column5     167180\n",
       "Column6       3850\n",
       "Column7          0\n",
       "Column8       3850\n",
       "Column9     732137\n",
       "Column10         0\n",
       "Column11         0\n",
       "Column12         0\n",
       "Column13         0\n",
       "Column14    365703\n",
       "Column15     16456\n",
       "Column16         0\n",
       "Column17         0\n",
       "Column18         0\n",
       "Column19         0\n",
       "Column20         0\n",
       "Column21         0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have too many missing values in the training data which must be handled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for missing values in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID               0\n",
       "Column0          2\n",
       "Column1          0\n",
       "Column2          0\n",
       "Column3      42234\n",
       "Column4      42710\n",
       "Column5      55659\n",
       "Column6       1234\n",
       "Column7          0\n",
       "Column8       1234\n",
       "Column9     243853\n",
       "Column10         0\n",
       "Column11         0\n",
       "Column12         0\n",
       "Column13         0\n",
       "Column14    121679\n",
       "Column15      5485\n",
       "Column16         0\n",
       "Column17         0\n",
       "Column18         0\n",
       "Column19         0\n",
       "Column20         0\n",
       "Column21         0\n",
       "target           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have too many missing values in the test data which must be handled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping off unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't need ID column for model trainig, hence we'll drop that column\n",
    "\n",
    "df_train = df_train.drop('ID', axis=True)\n",
    "df_test = df_test.drop('ID', axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are more than 80% missing values in Column9 and given that the column is standard scaled, it's better to drop the column\n",
    "\n",
    "df_train = df_train.drop('Column9', axis=True)\n",
    "df_test = df_test.drop('Column9', axis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram visualization for the standard scaled columns (which has missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_train['Column3'], bins=6, range=(-3, 3), color='grey', edgecolor='black')\n",
    "plt.title('Histogram of Column3 (Standard Scaled Values)')\n",
    "plt.xlabel('Values in Column3')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column3 has left-skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_train['Column4'], bins=6, range=(-3, 3), color='pink', edgecolor='black')\n",
    "plt.title('Histogram of Column4 (Standard Scaled Values)')\n",
    "plt.xlabel('Values in Column4')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column4 has left skewness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_train['Column6'], bins=6, range=(-3, 3), color='blue', edgecolor='black')\n",
    "plt.title('Histogram of Column6 (Standard Scaled Values)')\n",
    "plt.xlabel('Values in Column6')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column6 has right-skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_train['Column8'], bins=6, range=(-3, 3), color='red', edgecolor='black')\n",
    "plt.title('Histogram of Column8 (Standard Scaled Values)')\n",
    "plt.xlabel('Values in Column8')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column8 has right skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing the missing values with appropriate alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since Column0 is label encoded, we'll replace the missing values with mode\n",
    "\n",
    "mode_value_train = df_train['Column0'].mode()[0]\n",
    "df_train['Column0'] = df_train['Column0'].fillna(mode_value_train)\n",
    "\n",
    "mode_value_test = df_test['Column0'].mode()[0]\n",
    "df_test['Column0'] = df_test['Column0'].fillna(mode_value_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with median for Column 3,4,6,8 because the columns are skewed\n",
    "\n",
    "df_train['Column3'] = df_train['Column3'].fillna(df_train['Column3'].median())\n",
    "df_train['Column4'] = df_train['Column4'].fillna(df_train['Column4'].median())\n",
    "df_train['Column6'] = df_train['Column6'].fillna(df_train['Column6'].median())\n",
    "df_train['Column8'] = df_train['Column8'].fillna(df_train['Column8'].median())\n",
    "\n",
    "df_test['Column3'] = df_test['Column3'].fillna(df_test['Column3'].median())\n",
    "df_test['Column4'] = df_test['Column4'].fillna(df_test['Column4'].median())\n",
    "df_test['Column6'] = df_test['Column6'].fillna(df_test['Column6'].median())\n",
    "df_test['Column8'] = df_test['Column8'].fillna(df_test['Column8'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values with mode for Column5,14,15 because it contains only one value throughout the column\n",
    "\n",
    "df_train['Column5'] = df_train['Column5'].fillna(-0.007467888)\n",
    "df_train['Column14'] = df_train['Column14'].fillna(0.001350605)\n",
    "df_train['Column15'] = df_train['Column15'].fillna(0.003390099)\n",
    "\n",
    "df_test['Column5'] = df_test['Column5'].fillna(-0.007467888)\n",
    "df_test['Column14'] = df_test['Column14'].fillna(0.001350605)\n",
    "df_test['Column15'] = df_test['Column15'].fillna(0.003390099)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if there's any missing value left or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column0     0\n",
       "Column1     0\n",
       "Column2     0\n",
       "Column3     0\n",
       "Column4     0\n",
       "Column5     0\n",
       "Column6     0\n",
       "Column7     0\n",
       "Column8     0\n",
       "Column10    0\n",
       "Column11    0\n",
       "Column12    0\n",
       "Column13    0\n",
       "Column14    0\n",
       "Column15    0\n",
       "Column16    0\n",
       "Column17    0\n",
       "Column18    0\n",
       "Column19    0\n",
       "Column20    0\n",
       "Column21    0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column0     0\n",
       "Column1     0\n",
       "Column2     0\n",
       "Column3     0\n",
       "Column4     0\n",
       "Column5     0\n",
       "Column6     0\n",
       "Column7     0\n",
       "Column8     0\n",
       "Column10    0\n",
       "Column11    0\n",
       "Column12    0\n",
       "Column13    0\n",
       "Column14    0\n",
       "Column15    0\n",
       "Column16    0\n",
       "Column17    0\n",
       "Column18    0\n",
       "Column19    0\n",
       "Column20    0\n",
       "Column21    0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column0</th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>3726.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>0.434190</td>\n",
       "      <td>-0.015603</td>\n",
       "      <td>0.606265</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>0.452580</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>1.554998</td>\n",
       "      <td>-0.015574</td>\n",
       "      <td>0.329946</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2495</td>\n",
       "      <td>4543.0</td>\n",
       "      <td>-1.577453</td>\n",
       "      <td>-1.429540</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>211</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>718</td>\n",
       "      <td>950.0</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column0  Column1  Column2   Column3   Column4   Column5   Column6  \\\n",
       "0      2.0     2495   3726.0  0.678139  0.701403 -0.007468  0.434190   \n",
       "1      0.0     2495   3454.0  0.452580  0.701403 -0.007468  1.554998   \n",
       "2      2.0     2495   4543.0 -1.577453 -1.429540 -0.007469 -0.407939   \n",
       "3      0.0      211     59.0  0.678139  0.701403 -0.007468 -0.407939   \n",
       "4      0.0      718    950.0 -2.028572 -1.855728 -0.007468 -0.407939   \n",
       "\n",
       "    Column7   Column8  Column10  ...  Column13  Column14  Column15  Column16  \\\n",
       "0 -0.015603  0.606265         0  ...         0  0.001351   0.00339       0.0   \n",
       "1 -0.015574  0.329946         0  ...         0  0.001351   0.00339       0.0   \n",
       "2 -0.015607 -0.774979         1  ...         1  0.001351   0.00339       0.0   \n",
       "3 -0.015607 -0.774979         0  ...         0  0.001351   0.00339       0.0   \n",
       "4 -0.015607 -0.774979         0  ...         0  0.001351   0.00339       0.0   \n",
       "\n",
       "   Column17  Column18  Column19  Column20  Column21  target  \n",
       "0         0       0.0         0         0         0       0  \n",
       "1         0       0.0         0         0         0       0  \n",
       "2         0       0.0         0         0         0       0  \n",
       "3         0       1.0         0         0         0       1  \n",
       "4         0       0.0         0         0         0       0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column0</th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.554860</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1579</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.142149</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>898</td>\n",
       "      <td>3817.0</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>-0.675216</td>\n",
       "      <td>-0.577162</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.635264</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>646</td>\n",
       "      <td>6510.0</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015434</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column0  Column1  Column2   Column3   Column4   Column5   Column6  \\\n",
       "0      1.0     1986     53.0  0.678139  0.701403 -0.007469 -0.407939   \n",
       "1      2.0     1579     12.0  0.678139  0.701403 -0.007468 -0.407939   \n",
       "2      0.0      898   3817.0 -2.028572 -1.855728 -0.007468 -0.407939   \n",
       "3      0.0       79   3449.0 -0.675216 -0.577162 -0.007469  0.004020   \n",
       "4      1.0      646   6510.0 -2.028572 -1.855728 -0.007468 -0.407939   \n",
       "\n",
       "    Column7   Column8  Column10  ...  Column13  Column14  Column15  Column16  \\\n",
       "0 -0.015607  0.554860         1  ...         1  0.001351   0.00339       0.0   \n",
       "1 -0.015607  0.142149         0  ...         0  0.001351   0.00339       0.0   \n",
       "2 -0.015607 -0.774979         0  ...         0  0.001351   0.00339       0.0   \n",
       "3 -0.015607  0.635264         0  ...         1  0.001351   0.00339       0.0   \n",
       "4 -0.015434 -0.774979         1  ...         1  0.001351   0.00339       0.0   \n",
       "\n",
       "   Column17  Column18  Column19  Column20  Column21  target  \n",
       "0         0       0.0         0         0         0       0  \n",
       "1         0       0.0         0         0         0       0  \n",
       "2         0       0.0         0         0         0       0  \n",
       "3         0       0.0         0         0         0       0  \n",
       "4         0       0.0         0         0         0       0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Column1 and Column2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "df_train[['Column1', 'Column2']] = sc.fit_transform(df_train[['Column1', 'Column2']])\n",
    "df_test[['Column1', 'Column2']] = sc.fit_transform(df_test[['Column1', 'Column2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column0</th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.293126</td>\n",
       "      <td>0.361489</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>0.434190</td>\n",
       "      <td>-0.015603</td>\n",
       "      <td>0.606265</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.293126</td>\n",
       "      <td>0.234572</td>\n",
       "      <td>0.452580</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>1.554998</td>\n",
       "      <td>-0.015574</td>\n",
       "      <td>0.329946</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.293126</td>\n",
       "      <td>0.742705</td>\n",
       "      <td>-1.577453</td>\n",
       "      <td>-1.429540</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.224323</td>\n",
       "      <td>-1.349553</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.665502</td>\n",
       "      <td>-0.933808</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column0   Column1   Column2   Column3   Column4   Column5   Column6  \\\n",
       "0      2.0  1.293126  0.361489  0.678139  0.701403 -0.007468  0.434190   \n",
       "1      0.0  1.293126  0.234572  0.452580  0.701403 -0.007468  1.554998   \n",
       "2      2.0  1.293126  0.742705 -1.577453 -1.429540 -0.007469 -0.407939   \n",
       "3      0.0 -1.224323 -1.349553  0.678139  0.701403 -0.007468 -0.407939   \n",
       "4      0.0 -0.665502 -0.933808 -2.028572 -1.855728 -0.007468 -0.407939   \n",
       "\n",
       "    Column7   Column8  Column10  ...  Column13  Column14  Column15  Column16  \\\n",
       "0 -0.015603  0.606265         0  ...         0  0.001351   0.00339       0.0   \n",
       "1 -0.015574  0.329946         0  ...         0  0.001351   0.00339       0.0   \n",
       "2 -0.015607 -0.774979         1  ...         1  0.001351   0.00339       0.0   \n",
       "3 -0.015607 -0.774979         0  ...         0  0.001351   0.00339       0.0   \n",
       "4 -0.015607 -0.774979         0  ...         0  0.001351   0.00339       0.0   \n",
       "\n",
       "   Column17  Column18  Column19  Column20  Column21  target  \n",
       "0         0       0.0         0         0         0       0  \n",
       "1         0       0.0         0         0         0       0  \n",
       "2         0       0.0         0         0         0       0  \n",
       "3         0       1.0         0         0         0       1  \n",
       "4         0       0.0         0         0         0       0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column0</th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731650</td>\n",
       "      <td>-1.352041</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.554860</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.283555</td>\n",
       "      <td>-1.371134</td>\n",
       "      <td>0.678139</td>\n",
       "      <td>0.701403</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.142149</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.466207</td>\n",
       "      <td>0.400781</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.367903</td>\n",
       "      <td>0.229411</td>\n",
       "      <td>-0.675216</td>\n",
       "      <td>-0.577162</td>\n",
       "      <td>-0.007469</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>-0.015607</td>\n",
       "      <td>0.635264</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.743652</td>\n",
       "      <td>1.654859</td>\n",
       "      <td>-2.028572</td>\n",
       "      <td>-1.855728</td>\n",
       "      <td>-0.007468</td>\n",
       "      <td>-0.407939</td>\n",
       "      <td>-0.015434</td>\n",
       "      <td>-0.774979</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.00339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column0   Column1   Column2   Column3   Column4   Column5   Column6  \\\n",
       "0      1.0  0.731650 -1.352041  0.678139  0.701403 -0.007469 -0.407939   \n",
       "1      2.0  0.283555 -1.371134  0.678139  0.701403 -0.007468 -0.407939   \n",
       "2      0.0 -0.466207  0.400781 -2.028572 -1.855728 -0.007468 -0.407939   \n",
       "3      0.0 -1.367903  0.229411 -0.675216 -0.577162 -0.007469  0.004020   \n",
       "4      1.0 -0.743652  1.654859 -2.028572 -1.855728 -0.007468 -0.407939   \n",
       "\n",
       "    Column7   Column8  Column10  ...  Column13  Column14  Column15  Column16  \\\n",
       "0 -0.015607  0.554860         1  ...         1  0.001351   0.00339       0.0   \n",
       "1 -0.015607  0.142149         0  ...         0  0.001351   0.00339       0.0   \n",
       "2 -0.015607 -0.774979         0  ...         0  0.001351   0.00339       0.0   \n",
       "3 -0.015607  0.635264         0  ...         1  0.001351   0.00339       0.0   \n",
       "4 -0.015434 -0.774979         1  ...         1  0.001351   0.00339       0.0   \n",
       "\n",
       "   Column17  Column18  Column19  Column20  Column21  target  \n",
       "0         0       0.0         0         0         0       0  \n",
       "1         0       0.0         0         0         0       0  \n",
       "2         0       0.0         0         0         0       0  \n",
       "3         0       0.0         0         0         0       0  \n",
       "4         0       0.0         0         0         0       0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for the correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking correlation with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column0    -0.064454\n",
      "Column1    -0.374542\n",
      "Column2    -0.114910\n",
      "Column3     0.010895\n",
      "Column4    -0.001459\n",
      "Column5     0.000924\n",
      "Column6    -0.102544\n",
      "Column7    -0.004858\n",
      "Column8    -0.129188\n",
      "Column10   -0.097229\n",
      "Column11   -0.086418\n",
      "Column12   -0.128421\n",
      "Column13   -0.094361\n",
      "Column14    0.000404\n",
      "Column15   -0.006449\n",
      "Column16    0.087492\n",
      "Column17    0.248896\n",
      "Column18    0.727999\n",
      "Column19    0.258609\n",
      "Column20    0.135516\n",
      "Column21    0.119171\n",
      "target      1.000000\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = df_train.corr()\n",
    "correlation_with_target = correlation_matrix['target']\n",
    "print(correlation_with_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with very low correlation are Column3, Column4, Column5, Column7, Column14, Column15. Hence, we'll drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['Column3', 'Column4', 'Column5', 'Column7', 'Column14', 'Column15'], axis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for multicollinearity\n",
    "\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# X_train_df = pd.DataFrame(df_train, columns=[f'Column{i}' for i in range(X_train.shape[1])])\n",
    "\n",
    "# # Checking for multicollinearity in the training dataset\n",
    "# vif_data = pd.DataFrame()\n",
    "# vif_data[\"feature\"] = X_train_df.columns  \n",
    "# vif_data[\"VIF\"] = [variance_inflation_factor(X_train_df.values, i) for i in range(X_train_df.shape[1])]\n",
    "\n",
    "# # Print the VIF scores\n",
    "# print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with high multicollinearity (vif > 5) are Column4, Column9, Column10, Column11, Column12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[ : , :-1].values\n",
    "y_train = df_train.iloc[ : , -1].values\n",
    "\n",
    "X_test = df_test.iloc[ : , :-1].values\n",
    "y_test = df_test.iloc[ : , -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking whether out training data is balanced or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chekcing using Countplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df_train, x=\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is highly imbalanced. Hence we need to first balance it using SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE(random_state=42)\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 711100, 1: 711100})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data is now balanced. Now we can move towards model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Various Models for prediction/classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 21 features, but LogisticRegression is expecting 15 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m classifier\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Creating y_pred\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Cross-validation of model\u001b[39;00m\n\u001b[0;32m     16\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m cross_val_score(estimator\u001b[38;5;241m=\u001b[39mclassifier, X\u001b[38;5;241m=\u001b[39mX_train, y\u001b[38;5;241m=\u001b[39my_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\sklearn\\linear_model\\_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 351\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    353\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\sklearn\\linear_model\\_base.py:332\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    329\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    330\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 332\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 21 features, but LogisticRegression is expecting 15 features as input."
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Model building \n",
    "classifier = LogisticRegression(random_state=42, max_iter=1000, solver='lbfgs', n_jobs=-1)\n",
    "\n",
    "# Training the model on the resampled data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Creating y_pred\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Cross-validation of model\n",
    "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=5, n_jobs=-1)\n",
    "print('Cross-validation accuracy : ', accuracies.mean()*100, ' %')\n",
    "print('Cross-validation std: ', accuracies.std())\n",
    "\n",
    "# Printing the classification report and confusion matrix\n",
    "print(\"\\n\\n--- CLASSIFICATION REPORT ---\\n\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nCONFUSION MATRIX : \\n\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Model Building\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, metric='manhattan', n_jobs=-1)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Cross-validation of the model (Reduced folds for speed)\n",
    "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=3, n_jobs=-1) \n",
    "print('Accuracy mean: ', accuracies.mean() * 100, ' %')\n",
    "print('Accuracy std: ', accuracies.std())\n",
    "\n",
    "# Printing the classification report and confusion matrix\n",
    "print(\"\\n\\n--- CLASSIFICATION REPORT ---\\n\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nCONFUSION MATRIX : \\n\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Model building \n",
    "classifier = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=42, max_depth=15, n_jobs=-1)  \n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Creating y_pred\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Cross-validation of model\n",
    "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=5, n_jobs=-1)  \n",
    "print('Accuracy mean : ', accuracies.mean()*100,' %')\n",
    "print('Accuracy std: ', accuracies.std())\n",
    "\n",
    "# Printing the classification report and confusion matrix\n",
    "print(\"\\n\\n--- CLASSIFICATION REPORT ---\\n\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nCONFUSION MATRIX : \\n\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning of Decision Tree Classifier Model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the model\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid, scoring='precision', cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model to the oversampled training data (X_train, y_train)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "print(f'Best Parameters: {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Model building\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion='gini', max_depth=15, min_samples_leaf=4, min_samples_split=2, random_state=42)  \n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Creating y_pred\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Cross-validation of model\n",
    "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=5)\n",
    "print('Accuracy mean : ', accuracies.mean()*100, ' %')\n",
    "print('Accuracy std: ', accuracies.std())\n",
    "\n",
    "# Printing the classification report and confusion matrix\n",
    "print(\"\\n\\n--- CLASSIFICATION REPORT ---\\n\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nCONFUSION MATRIX : \\n\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building ANN\n",
    "\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize the ANN\n",
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "# Adjust input layer size based on the number of features\n",
    "ann.add(tf.keras.layers.Dense(units=21, activation='relu'))\n",
    "\n",
    "# Add hidden layers\n",
    "ann.add(tf.keras.layers.Dense(units=21, activation='relu'))\n",
    "ann.add(tf.keras.layers.Dense(units=21, activation='relu'))  # Adding another hidden layer for complexity\n",
    "\n",
    "# Add output layer\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the ANN\n",
    "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Implement early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the ANN with validation split\n",
    "ann.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Predict the results\n",
    "y_pred = (ann.predict(X_test) > 0.7).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the classification report and confusion matrix\n",
    "# Printing the classification report and confusion matrix\n",
    "print(\"\\n\\n--- CLASSIFICATION REPORT ---\\n\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nCONFUSION MATRIX : \\n\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the dedicated GPU of your laptop for running the code, you need to ensure that your environment is set up to utilize the GPU. This typically involves installing the GPU version of TensorFlow and ensuring that your system has the necessary drivers and CUDA toolkit installed.\n",
    "\n",
    "Here's how you can modify your code to ensure that TensorFlow uses the GPU:\n",
    "\n",
    "1. **Install the GPU version of TensorFlow**:\n",
    "    ```bash\n",
    "    pip install tensorflow-gpu\n",
    "    ```\n",
    "\n",
    "2. **Verify that TensorFlow is using the GPU**:\n",
    "    Add the following code at the beginning of your script to check if TensorFlow is using the GPU:\n",
    "\n",
    "    ```python\n",
    "    import tensorflow as tf\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    ```\n",
    "\n",
    "3. **Modify your existing code to ensure TensorFlow uses the GPU**:\n",
    "    ```python  \n",
    "  \n",
    "    ```\n",
    "\n",
    "Make sure that your system has the necessary NVIDIA drivers and CUDA toolkit installed. You can follow the [TensorFlow GPU support guide](https://www.tensorflow.org/install/gpu) for detailed instructions on setting up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print (\"Num GPUs Available: \",\n",
    "len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_37309 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_37309_row0_col0, #T_37309_row0_col3, #T_37309_row0_col4, #T_37309_row0_col7, #T_37309_row1_col0, #T_37309_row1_col2, #T_37309_row1_col3, #T_37309_row1_col4, #T_37309_row2_col0, #T_37309_row2_col2, #T_37309_row2_col3, #T_37309_row2_col4, #T_37309_row2_col6, #T_37309_row2_col7, #T_37309_row3_col0, #T_37309_row3_col1, #T_37309_row3_col2, #T_37309_row3_col3, #T_37309_row3_col4, #T_37309_row3_col5, #T_37309_row3_col6, #T_37309_row3_col7, #T_37309_row4_col0, #T_37309_row4_col1, #T_37309_row4_col2, #T_37309_row4_col3, #T_37309_row4_col4, #T_37309_row4_col5, #T_37309_row4_col6, #T_37309_row4_col7, #T_37309_row5_col0, #T_37309_row5_col1, #T_37309_row5_col2, #T_37309_row5_col3, #T_37309_row5_col4, #T_37309_row5_col5, #T_37309_row5_col6, #T_37309_row5_col7, #T_37309_row6_col0, #T_37309_row6_col1, #T_37309_row6_col2, #T_37309_row6_col3, #T_37309_row6_col4, #T_37309_row6_col5, #T_37309_row6_col6, #T_37309_row6_col7, #T_37309_row7_col0, #T_37309_row7_col1, #T_37309_row7_col2, #T_37309_row7_col4, #T_37309_row7_col5, #T_37309_row7_col6, #T_37309_row7_col7, #T_37309_row8_col0, #T_37309_row8_col1, #T_37309_row8_col2, #T_37309_row8_col3, #T_37309_row8_col4, #T_37309_row8_col5, #T_37309_row8_col6, #T_37309_row8_col7, #T_37309_row9_col0, #T_37309_row9_col1, #T_37309_row9_col2, #T_37309_row9_col3, #T_37309_row9_col5, #T_37309_row9_col6, #T_37309_row9_col7, #T_37309_row10_col0, #T_37309_row10_col1, #T_37309_row10_col2, #T_37309_row10_col3, #T_37309_row10_col4, #T_37309_row10_col5, #T_37309_row10_col6, #T_37309_row10_col7, #T_37309_row11_col0, #T_37309_row11_col1, #T_37309_row11_col2, #T_37309_row11_col3, #T_37309_row11_col4, #T_37309_row11_col5, #T_37309_row11_col6, #T_37309_row11_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_37309_row0_col1, #T_37309_row0_col2, #T_37309_row0_col5, #T_37309_row0_col6, #T_37309_row1_col1, #T_37309_row1_col5, #T_37309_row1_col6, #T_37309_row1_col7, #T_37309_row2_col1, #T_37309_row2_col5, #T_37309_row7_col3, #T_37309_row9_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_37309_row0_col8, #T_37309_row1_col8, #T_37309_row2_col8, #T_37309_row3_col8, #T_37309_row4_col8, #T_37309_row5_col8, #T_37309_row6_col8, #T_37309_row7_col8, #T_37309_row9_col8, #T_37309_row10_col8, #T_37309_row11_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_37309_row8_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_37309\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_37309_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_37309_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_37309_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_37309_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_37309_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_37309_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_37309_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_37309_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_37309_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_37309_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
       "      <td id=\"T_37309_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_37309_row0_col1\" class=\"data row0 col1\" >0.9836</td>\n",
       "      <td id=\"T_37309_row0_col2\" class=\"data row0 col2\" >0.9950</td>\n",
       "      <td id=\"T_37309_row0_col3\" class=\"data row0 col3\" >0.9965</td>\n",
       "      <td id=\"T_37309_row0_col4\" class=\"data row0 col4\" >0.9714</td>\n",
       "      <td id=\"T_37309_row0_col5\" class=\"data row0 col5\" >0.9838</td>\n",
       "      <td id=\"T_37309_row0_col6\" class=\"data row0 col6\" >0.9672</td>\n",
       "      <td id=\"T_37309_row0_col7\" class=\"data row0 col7\" >0.9675</td>\n",
       "      <td id=\"T_37309_row0_col8\" class=\"data row0 col8\" >52.7210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37309_level0_row1\" class=\"row_heading level0 row1\" >knn</th>\n",
       "      <td id=\"T_37309_row1_col0\" class=\"data row1 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_37309_row1_col1\" class=\"data row1 col1\" >0.9836</td>\n",
       "      <td id=\"T_37309_row1_col2\" class=\"data row1 col2\" >0.9895</td>\n",
       "      <td id=\"T_37309_row1_col3\" class=\"data row1 col3\" >0.9988</td>\n",
       "      <td id=\"T_37309_row1_col4\" class=\"data row1 col4\" >0.9693</td>\n",
       "      <td id=\"T_37309_row1_col5\" class=\"data row1 col5\" >0.9838</td>\n",
       "      <td id=\"T_37309_row1_col6\" class=\"data row1 col6\" >0.9672</td>\n",
       "      <td id=\"T_37309_row1_col7\" class=\"data row1 col7\" >0.9677</td>\n",
       "      <td id=\"T_37309_row1_col8\" class=\"data row1 col8\" >70.8480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37309_level0_row2\" class=\"row_heading level0 row2\" >et</th>\n",
       "      <td id=\"T_37309_row2_col0\" class=\"data row2 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_37309_row2_col1\" class=\"data row2 col1\" >0.9836</td>\n",
       "      <td id=\"T_37309_row2_col2\" class=\"data row2 col2\" >0.9948</td>\n",
       "      <td id=\"T_37309_row2_col3\" class=\"data row2 col3\" >0.9959</td>\n",
       "      <td id=\"T_37309_row2_col4\" class=\"data row2 col4\" >0.9719</td>\n",
       "      <td id=\"T_37309_row2_col5\" class=\"data row2 col5\" >0.9838</td>\n",
       "      <td id=\"T_37309_row2_col6\" class=\"data row2 col6\" >0.9671</td>\n",
       "      <td id=\"T_37309_row2_col7\" class=\"data row2 col7\" >0.9674</td>\n",
       "      <td id=\"T_37309_row2_col8\" class=\"data row2 col8\" >51.6010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37309_level0_row3\" class=\"row_heading level0 row3\" >lightgbm</th>\n",
       "      <td id=\"T_37309_row3_col0\" class=\"data row3 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_37309_row3_col1\" class=\"data row3 col1\" >0.9828</td>\n",
       "      <td id=\"T_37309_row3_col2\" class=\"data row3 col2\" >0.9941</td>\n",
       "      <td id=\"T_37309_row3_col3\" class=\"data row3 col3\" >0.9994</td>\n",
       "      <td id=\"T_37309_row3_col4\" class=\"data row3 col4\" >0.9672</td>\n",
       "      <td id=\"T_37309_row3_col5\" class=\"data row3 col5\" >0.9830</td>\n",
       "      <td id=\"T_37309_row3_col6\" class=\"data row3 col6\" >0.9655</td>\n",
       "      <td id=\"T_37309_row3_col7\" class=\"data row3 col7\" >0.9661</td>\n",
       "      <td id=\"T_37309_row3_col8\" class=\"data row3 col8\" >4.3720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37309_level0_row4\" class=\"row_heading level0 row4\" >gbc</th>\n",
       "      <td id=\"T_37309_row4_col0\" class=\"data row4 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_37309_row4_col1\" class=\"data row4 col1\" >0.9822</td>\n",
       "      <td id=\"T_37309_row4_col2\" class=\"data row4 col2\" >0.9934</td>\n",
       "      <td id=\"T_37309_row4_col3\" class=\"data row4 col3\" >0.9996</td>\n",
       "      <td id=\"T_37309_row4_col4\" class=\"data row4 col4\" >0.9660</td>\n",
       "      <td id=\"T_37309_row4_col5\" class=\"data row4 col5\" >0.9825</td>\n",
       "      <td id=\"T_37309_row4_col6\" class=\"data row4 col6\" >0.9644</td>\n",
       "      <td id=\"T_37309_row4_col7\" class=\"data row4 col7\" >0.9650</td>\n",
       "      <td id=\"T_37309_row4_col8\" class=\"data row4 col8\" >58.7920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37309_level0_row5\" class=\"row_heading level0 row5\" >ada</th>\n",
       "      <td id=\"T_37309_row5_col0\" class=\"data row5 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_37309_row5_col1\" class=\"data row5 col1\" >0.9818</td>\n",
       "      <td id=\"T_37309_row5_col2\" class=\"data row5 col2\" >0.9930</td>\n",
       "      <td id=\"T_37309_row5_col3\" class=\"data row5 col3\" >0.9994</td>\n",
       "      <td id=\"T_37309_row5_col4\" class=\"data row5 col4\" >0.9655</td>\n",
       "      <td id=\"T_37309_row5_col5\" class=\"data row5 col5\" >0.9822</td>\n",
       "      <td id=\"T_37309_row5_col6\" class=\"data row5 col6\" >0.9637</td>\n",
       "      <td id=\"T_37309_row5_col7\" class=\"data row5 col7\" >0.9643</td>\n",
       "      <td id=\"T_37309_row5_col8\" class=\"data row5 col8\" >15.9230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37309_level0_row6\" class=\"row_heading level0 row6\" >lr</th>\n",
       "      <td id=\"T_37309_row6_col0\" class=\"data row6 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_37309_row6_col1\" class=\"data row6 col1\" >0.9806</td>\n",
       "      <td id=\"T_37309_row6_col2\" class=\"data row6 col2\" >0.9888</td>\n",
       "      <td id=\"T_37309_row6_col3\" class=\"data row6 col3\" >0.9998</td>\n",
       "      <td id=\"T_37309_row6_col4\" class=\"data row6 col4\" >0.9629</td>\n",
       "      <td id=\"T_37309_row6_col5\" class=\"data row6 col5\" >0.9810</td>\n",
       "      <td id=\"T_37309_row6_col6\" class=\"data row6 col6\" >0.9612</td>\n",
       "      <td id=\"T_37309_row6_col7\" class=\"data row6 col7\" >0.9619</td>\n",
       "      <td id=\"T_37309_row6_col8\" class=\"data row6 col8\" >1.4270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37309_level0_row7\" class=\"row_heading level0 row7\" >svm</th>\n",
       "      <td id=\"T_37309_row7_col0\" class=\"data row7 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_37309_row7_col1\" class=\"data row7 col1\" >0.9800</td>\n",
       "      <td id=\"T_37309_row7_col2\" class=\"data row7 col2\" >0.9873</td>\n",
       "      <td id=\"T_37309_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_37309_row7_col4\" class=\"data row7 col4\" >0.9615</td>\n",
       "      <td id=\"T_37309_row7_col5\" class=\"data row7 col5\" >0.9804</td>\n",
       "      <td id=\"T_37309_row7_col6\" class=\"data row7 col6\" >0.9600</td>\n",
       "      <td id=\"T_37309_row7_col7\" class=\"data row7 col7\" >0.9607</td>\n",
       "      <td id=\"T_37309_row7_col8\" class=\"data row7 col8\" >0.7580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37309_level0_row8\" class=\"row_heading level0 row8\" >ridge</th>\n",
       "      <td id=\"T_37309_row8_col0\" class=\"data row8 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_37309_row8_col1\" class=\"data row8 col1\" >0.9786</td>\n",
       "      <td id=\"T_37309_row8_col2\" class=\"data row8 col2\" >0.9884</td>\n",
       "      <td id=\"T_37309_row8_col3\" class=\"data row8 col3\" >0.9919</td>\n",
       "      <td id=\"T_37309_row8_col4\" class=\"data row8 col4\" >0.9662</td>\n",
       "      <td id=\"T_37309_row8_col5\" class=\"data row8 col5\" >0.9789</td>\n",
       "      <td id=\"T_37309_row8_col6\" class=\"data row8 col6\" >0.9573</td>\n",
       "      <td id=\"T_37309_row8_col7\" class=\"data row8 col7\" >0.9576</td>\n",
       "      <td id=\"T_37309_row8_col8\" class=\"data row8 col8\" >0.4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37309_level0_row9\" class=\"row_heading level0 row9\" >dt</th>\n",
       "      <td id=\"T_37309_row9_col0\" class=\"data row9 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_37309_row9_col1\" class=\"data row9 col1\" >0.9757</td>\n",
       "      <td id=\"T_37309_row9_col2\" class=\"data row9 col2\" >0.9759</td>\n",
       "      <td id=\"T_37309_row9_col3\" class=\"data row9 col3\" >0.9769</td>\n",
       "      <td id=\"T_37309_row9_col4\" class=\"data row9 col4\" >0.9747</td>\n",
       "      <td id=\"T_37309_row9_col5\" class=\"data row9 col5\" >0.9758</td>\n",
       "      <td id=\"T_37309_row9_col6\" class=\"data row9 col6\" >0.9515</td>\n",
       "      <td id=\"T_37309_row9_col7\" class=\"data row9 col7\" >0.9515</td>\n",
       "      <td id=\"T_37309_row9_col8\" class=\"data row9 col8\" >2.4860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37309_level0_row10\" class=\"row_heading level0 row10\" >nb</th>\n",
       "      <td id=\"T_37309_row10_col0\" class=\"data row10 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_37309_row10_col1\" class=\"data row10 col1\" >0.8884</td>\n",
       "      <td id=\"T_37309_row10_col2\" class=\"data row10 col2\" >0.9561</td>\n",
       "      <td id=\"T_37309_row10_col3\" class=\"data row10 col3\" >0.8059</td>\n",
       "      <td id=\"T_37309_row10_col4\" class=\"data row10 col4\" >0.9653</td>\n",
       "      <td id=\"T_37309_row10_col5\" class=\"data row10 col5\" >0.8784</td>\n",
       "      <td id=\"T_37309_row10_col6\" class=\"data row10 col6\" >0.7769</td>\n",
       "      <td id=\"T_37309_row10_col7\" class=\"data row10 col7\" >0.7877</td>\n",
       "      <td id=\"T_37309_row10_col8\" class=\"data row10 col8\" >0.4560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_37309_level0_row11\" class=\"row_heading level0 row11\" >qda</th>\n",
       "      <td id=\"T_37309_row11_col0\" class=\"data row11 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_37309_row11_col1\" class=\"data row11 col1\" >0.8684</td>\n",
       "      <td id=\"T_37309_row11_col2\" class=\"data row11 col2\" >0.9634</td>\n",
       "      <td id=\"T_37309_row11_col3\" class=\"data row11 col3\" >0.7644</td>\n",
       "      <td id=\"T_37309_row11_col4\" class=\"data row11 col4\" >0.9652</td>\n",
       "      <td id=\"T_37309_row11_col5\" class=\"data row11 col5\" >0.8531</td>\n",
       "      <td id=\"T_37309_row11_col6\" class=\"data row11 col6\" >0.7368</td>\n",
       "      <td id=\"T_37309_row11_col7\" class=\"data row11 col7\" >0.7533</td>\n",
       "      <td id=\"T_37309_row11_col8\" class=\"data row11 col8\" >1.0330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x25a811af730>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>00:33:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Searching Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         \n",
       "                                                                         \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                   00:33:54\n",
       "Status     . . . . . . . . . . . . . . . . . .  Searching Hyperparameters\n",
       "Estimator  . . . . . . . . . . . . . . . . . .   Random Forest Classifier"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13378b5c89d347fbb6959abae95012fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m best_model \u001b[38;5;241m=\u001b[39m compare_models(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgbm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknn\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqda\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mada\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124met\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mridge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvm\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Step 5: Fine-tune the best model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m tuned_model \u001b[38;5;241m=\u001b[39m \u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Step 6: Finalize the model (this locks the model and prepares it for final predictions)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m final_model \u001b[38;5;241m=\u001b[39m finalize_model(tuned_model)\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\pycaret\\utils\\generic.py:964\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m globals_d[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\pycaret\\classification\\functional.py:1208\u001b[0m, in \u001b[0;36mtune_model\u001b[1;34m(estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;129m@check_if_global_is_not_none\u001b[39m(\u001b[38;5;28mglobals\u001b[39m(), _CURRENT_EXPERIMENT_DECORATOR_DICT)\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[0;32m   1019\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1038\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \n\u001b[0;32m   1206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _CURRENT_EXPERIMENT\u001b[38;5;241m.\u001b[39mtune_model(\n\u001b[0;32m   1209\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1210\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   1211\u001b[0m         \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   1212\u001b[0m         n_iter\u001b[38;5;241m=\u001b[39mn_iter,\n\u001b[0;32m   1213\u001b[0m         custom_grid\u001b[38;5;241m=\u001b[39mcustom_grid,\n\u001b[0;32m   1214\u001b[0m         optimize\u001b[38;5;241m=\u001b[39moptimize,\n\u001b[0;32m   1215\u001b[0m         custom_scorer\u001b[38;5;241m=\u001b[39mcustom_scorer,\n\u001b[0;32m   1216\u001b[0m         search_library\u001b[38;5;241m=\u001b[39msearch_library,\n\u001b[0;32m   1217\u001b[0m         search_algorithm\u001b[38;5;241m=\u001b[39msearch_algorithm,\n\u001b[0;32m   1218\u001b[0m         early_stopping\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[0;32m   1219\u001b[0m         early_stopping_max_iters\u001b[38;5;241m=\u001b[39mearly_stopping_max_iters,\n\u001b[0;32m   1220\u001b[0m         choose_better\u001b[38;5;241m=\u001b[39mchoose_better,\n\u001b[0;32m   1221\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1222\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1223\u001b[0m         return_tuner\u001b[38;5;241m=\u001b[39mreturn_tuner,\n\u001b[0;32m   1224\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1225\u001b[0m         tuner_verbose\u001b[38;5;241m=\u001b[39mtuner_verbose,\n\u001b[0;32m   1226\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   1227\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1228\u001b[0m     )\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\pycaret\\classification\\oop.py:1558\u001b[0m, in \u001b[0;36mClassificationExperiment.tune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[0;32m   1368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1369\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1388\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \n\u001b[0;32m   1556\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtune_model(\n\u001b[0;32m   1559\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1560\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;28mround\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m,\n\u001b[0;32m   1562\u001b[0m         n_iter\u001b[38;5;241m=\u001b[39mn_iter,\n\u001b[0;32m   1563\u001b[0m         custom_grid\u001b[38;5;241m=\u001b[39mcustom_grid,\n\u001b[0;32m   1564\u001b[0m         optimize\u001b[38;5;241m=\u001b[39moptimize,\n\u001b[0;32m   1565\u001b[0m         custom_scorer\u001b[38;5;241m=\u001b[39mcustom_scorer,\n\u001b[0;32m   1566\u001b[0m         search_library\u001b[38;5;241m=\u001b[39msearch_library,\n\u001b[0;32m   1567\u001b[0m         search_algorithm\u001b[38;5;241m=\u001b[39msearch_algorithm,\n\u001b[0;32m   1568\u001b[0m         early_stopping\u001b[38;5;241m=\u001b[39mearly_stopping,\n\u001b[0;32m   1569\u001b[0m         early_stopping_max_iters\u001b[38;5;241m=\u001b[39mearly_stopping_max_iters,\n\u001b[0;32m   1570\u001b[0m         choose_better\u001b[38;5;241m=\u001b[39mchoose_better,\n\u001b[0;32m   1571\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1572\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1573\u001b[0m         return_tuner\u001b[38;5;241m=\u001b[39mreturn_tuner,\n\u001b[0;32m   1574\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1575\u001b[0m         tuner_verbose\u001b[38;5;241m=\u001b[39mtuner_verbose,\n\u001b[0;32m   1576\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[0;32m   1577\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1578\u001b[0m     )\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:2680\u001b[0m, in \u001b[0;36m_SupervisedExperiment.tune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   2672\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch(\n\u001b[0;32m   2673\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection._search.sample_without_replacement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2674\u001b[0m         pycaret\u001b[38;5;241m.\u001b[39minternal\u001b[38;5;241m.\u001b[39mpatches\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39m_mp_sample_without_replacement,\n\u001b[0;32m   2675\u001b[0m     ):\n\u001b[0;32m   2676\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m patch(\n\u001b[0;32m   2677\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection._search.ParameterGrid.__getitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2678\u001b[0m             pycaret\u001b[38;5;241m.\u001b[39minternal\u001b[38;5;241m.\u001b[39mpatches\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39m_mp_ParameterGrid_getitem,\n\u001b[0;32m   2679\u001b[0m         ):\n\u001b[1;32m-> 2680\u001b[0m             model_grid\u001b[38;5;241m.\u001b[39mfit(data_X, data_y, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m   2681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2682\u001b[0m     model_grid\u001b[38;5;241m.\u001b[39mfit(data_X, data_y, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1916\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32me:\\GSTIN-1\\pycaret-env\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "    # Step 1: Install and import PyCaret\n",
    "import pandas as pd\n",
    "import pycaret\n",
    "from pycaret.classification import setup, compare_models, tune_model, finalize_model, evaluate_model, predict_model\n",
    "\n",
    "    # Concatenate the features and target into a single DataFrame\n",
    "data = pd.concat([pd.DataFrame(X_train), pd.DataFrame(y_train, columns=['target'])], axis=1)\n",
    "\n",
    "    # Step 3: Initialize the PyCaret setup for classification\n",
    "clf_setup = setup(data=data, target='target', session_id=42, train_size=0.8, verbose=False)\n",
    "\n",
    "    # Step 4: Compare multiple models to find the best one\n",
    "best_model = compare_models(include=['lightgbm', 'lr', 'dt', 'rf', 'knn', 'nb', 'qda', 'ada', 'gbc', 'et', 'ridge', 'svm'])\n",
    "\n",
    "    # Step 5: Fine-tune the best model\n",
    "tuned_model = tune_model(best_model)\n",
    "\n",
    "    # Step 6: Finalize the model (this locks the model and prepares it for final predictions)\n",
    "final_model = finalize_model(tuned_model)\n",
    "\n",
    "    # Step 7: Evaluate the model on unseen test data (X_test and y_test)\n",
    "    # Convert X_test to a DataFrame (PyCaret requires DataFrame input)\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "\n",
    "    # Get predictions on test data\n",
    "predictions = predict_model(final_model, data=X_test_df)\n",
    "\n",
    "    # Print the predictions\n",
    "print(predictions.head())\n",
    "\n",
    "    # Step 8: Evaluate the model (optional, visual evaluation)\n",
    "evaluate_model(final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a random forest model based on the previous result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X: 785133\n",
      "Length of y: 1570266\n",
      "Truncated lengths - X: 785133, y: 785133\n",
      "Accuracy: 0.9530908697230412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "X = pd.read_csv('X_Train_Data_Input.csv')\n",
    "y = pd.read_csv('Y_Train_Data_Target.csv').values.ravel()\n",
    "\n",
    "# Debugging: Print lengths of X and y\n",
    "print(f'Length of X: {len(X)}')\n",
    "print(f'Length of y: {len(y)}')\n",
    "\n",
    "# Ensure consistent lengths\n",
    "if len(X) != len(y):\n",
    "    # Truncate the longer dataset to match the shorter one\n",
    "    min_length = min(len(X), len(y))\n",
    "    X = X.iloc[:min_length]\n",
    "    y = y[:min_length]\n",
    "    print(f'Truncated lengths - X: {len(X)}, y: {len(y)}')\n",
    "\n",
    "# Identify high cardinality features\n",
    "high_cardinality_features = [col for col in X.columns if X[col].nunique() > 1000]\n",
    "\n",
    "# Use label encoding for high cardinality features\n",
    "label_encoders = {}\n",
    "for col in high_cardinality_features:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Use one-hot encoding for the remaining features\n",
    "X = pd.get_dummies(X, columns=[col for col in X.columns if col not in high_cardinality_features])\n",
    "\n",
    "# Ensure all features are numeric\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle any remaining NaN values\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Ensure target variable y is numeric\n",
    "y = pd.to_numeric(y, errors='coerce')\n",
    "\n",
    "# Convert y to a pandas Series to use fillna\n",
    "y = pd.Series(y).fillna(0).astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n",
      "C:\\Users\\UTSAV CHANDRA\\AppData\\Local\\Temp\\ipykernel_18140\\3228810903.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_new[col] = 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load('model.pkl')\n",
    "\n",
    "# Example new data (replace with actual new data)\n",
    "X_new_raw = pd.DataFrame({\n",
    "    'feature1': [5.1],\n",
    "    'feature2': [3.5],\n",
    "    'feature3': [1.4],\n",
    "    'feature4': [0.2]\n",
    "    # Add other features as needed\n",
    "})\n",
    "\n",
    "# Preprocess the new data\n",
    "# Identify high cardinality features (same as during training)\n",
    "high_cardinality_features = [col for col in X_new_raw.columns if X_new_raw[col].nunique() > 1000]\n",
    "\n",
    "# Use label encoding for high cardinality features\n",
    "label_encoders = {}  # Load or define the same label encoders used during training\n",
    "for col in high_cardinality_features:\n",
    "    le = label_encoders.get(col, LabelEncoder())\n",
    "    X_new_raw[col] = le.fit_transform(X_new_raw[col].astype(str))\n",
    "\n",
    "# Use one-hot encoding for the remaining features\n",
    "X_new = pd.get_dummies(X_new_raw, columns=[col for col in X_new_raw.columns if col not in high_cardinality_features])\n",
    "\n",
    "# Ensure all features are numeric\n",
    "X_new = X_new.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle any remaining NaN values\n",
    "X_new = X_new.fillna(0)\n",
    "\n",
    "# Ensure the new data has the same number of features as the training data\n",
    "# This might involve adding missing columns with default values\n",
    "missing_cols = set(model.feature_names_in_) - set(X_new.columns)\n",
    "for col in missing_cols:\n",
    "    X_new[col] = 0\n",
    "\n",
    "# Reorder columns to match the training data\n",
    "X_new = X_new[model.feature_names_in_]\n",
    "\n",
    "# Make predictions\n",
    "y_new = model.predict(X_new)\n",
    "print(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy, precision, recall, F1 score, and AUC-ROC.\n",
    "Display the confusion matrix.\n",
    "Optionally, calculate and display log loss and balanced accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X: 261712\n",
      "Length of y: 261712\n",
      "Accuracy: 0.9729476720860478\n",
      "Precision: 0.906657481246271\n",
      "Recall: 0.9447247994901009\n",
      "F1 Score: 0.9245817054093943\n",
      "AUC-ROC: 0.9921966811723152\n",
      "Confusion Matrix: \n",
      "[[46422   970]\n",
      " [  446  4505]]\n",
      "Log Loss: 0.07190963863994328\n",
      "Balanced Accuracy: 0.9447247994901009\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, log_loss, balanced_accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "X = pd.read_csv('X_Test_Data_Input.csv')\n",
    "y = pd.read_csv('Y_Test_Data_Target.csv')\n",
    "\n",
    "# Ensure y is a 1D array by selecting the appropriate column\n",
    "# Assuming the target column is named 'target' or similar\n",
    "y = y['target'].values.ravel()\n",
    "\n",
    "# Debugging: Print lengths of X and y\n",
    "print(f'Length of X: {len(X)}')\n",
    "print(f'Length of y: {len(y)}')\n",
    "\n",
    "# Ensure consistent lengths\n",
    "if len(X) != len(y):\n",
    "    # Truncate the longer dataset to match the shorter one\n",
    "    min_length = min(len(X), len(y))\n",
    "    X = X.iloc[:min_length]\n",
    "    y = y[:min_length]\n",
    "    print(f'Truncated lengths - X: {len(X)}, y: {len(y)}')\n",
    "\n",
    "# Handle non-numeric values\n",
    "# Identify high cardinality features\n",
    "high_cardinality_features = [col for col in X.columns if X[col].nunique() > 1000]\n",
    "\n",
    "# Use label encoding for high cardinality features\n",
    "label_encoders = {}\n",
    "for col in high_cardinality_features:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Use one-hot encoding for the remaining features\n",
    "X = pd.get_dummies(X, columns=[col for col in X.columns if col not in high_cardinality_features])\n",
    "\n",
    "# Ensure all features are numeric\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle any remaining NaN values\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Ensure target variable y is numeric\n",
    "y = pd.to_numeric(y, errors='coerce')\n",
    "\n",
    "# Convert y to a pandas Series to use fillna\n",
    "y = pd.Series(y).fillna(0).astype(int)\n",
    "\n",
    "# Ensure y is a 1D array\n",
    "y = y.values.ravel()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Calculate Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "# Ensure y_test is a 1D array\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# Calculate metrics\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba[:, 1], multi_class='ovr')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "log_loss_value = log_loss(y_test, y_pred_proba)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print Metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'AUC-ROC: {auc_roc}')\n",
    "print(f'Confusion Matrix: \\n{conf_matrix}')\n",
    "print(f'Log Loss: {log_loss_value}')\n",
    "print(f'Balanced Accuracy: {balanced_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
